{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp\n",
    "from surprise import BaselineOnly\n",
    "from surprise import CoClustering\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, SlopeOne\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def get_users(line):\n",
    "    row, col = line.split(\"_\")\n",
    "    row = row.replace(\"r\", \"\")\n",
    "    return int(row)\n",
    "def get_items(line):\n",
    "    row, col = line.split(\"_\")\n",
    "    col = col.replace(\"c\", \"\")\n",
    "    return int(col)\n",
    "def adapt_prediction_in_matrix(predictions):\n",
    "    X = []\n",
    "    for pred in predictions:\n",
    "        Y = []\n",
    "        pred.sort()\n",
    "        for pre in pred:\n",
    "            Y.append(pre.est)\n",
    "        X.append(Y)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0      44       1       4\n",
       "1      61       1       3\n",
       "2      67       1       4\n",
       "3      72       1       3\n",
       "4      86       1       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_train.csv')\n",
    "data['userID'] = data['Id'].apply(get_users)\n",
    "data['itemID'] = data['Id'].apply(get_items)\n",
    "data = data.drop('Id', axis=1)\n",
    "data = data.rename(columns={'Prediction':'rating'})[['userID','itemID','rating']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "surp = Dataset.load_from_df(data, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines options for the different algorithms used\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               }\n",
    "sim_options = {'name': 'pearson_baseline'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines the list of algos to be blended\n",
    "algos = [SlopeOne(),\n",
    "         KNNBaseline(k=60,sim_options=sim_options, bsl_options=bsl_options), \n",
    "         CoClustering(),\n",
    "         SVDpp()\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlendingCoefficients(algos):\n",
    "    \"\"\"Creates a k-fold validation on the data \n",
    "    with all the specified algorithms \n",
    "    and then tests is at every-fold time \n",
    "    to have different coefficient for blending\n",
    "    input : algos  : to be tested\n",
    "    outputs : vector of the coefficient of the best parameters\"\"\"\n",
    "    \n",
    "    print('splits the data set') \n",
    "    train_set, test_set = train_test_split(surp)\n",
    "    \n",
    "    print('fits the algos on the train_set')\n",
    "    for algo in algos:\n",
    "        algo.fit(train_set)\n",
    "    \n",
    "    print('test the alogs on the test set')\n",
    "    predictions = []\n",
    "    for algo in algos:\n",
    "        prediction = algo.test(test_set)\n",
    "        predictions.append(prediction)\n",
    "        accuracy.rmse(prediction, verbose=True)\n",
    "        \n",
    "    print('calculates the blending coefficients')\n",
    "    \n",
    "    X = adapt_prediction_in_matrix(predictions)\n",
    "    \n",
    "    test_set.sort()\n",
    "    test_set = np.array(test_set)\n",
    "    reg = linear_model.LinearRegression().fit(np.transpose(X), test_set[:,2])\n",
    "    \n",
    "    return reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits the data set\n",
      "fits the algos on the train_set\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "test the alogs on the test set\n",
      "RMSE: 1.0006\n",
      "RMSE: 0.9968\n",
      "RMSE: 1.0120\n",
      "RMSE: 1.0173\n",
      "calculates the blending coefficients\n"
     ]
    }
   ],
   "source": [
    "coefs = getBlendingCoefficients(algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23670371,  0.50315915, -0.07752119,  0.3256102 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that you need to fit the algos on the whole train set this time to have the final result\n",
    "train_set = surp.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('examples_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['userID'] = test['Id'].apply(get_users)\n",
    "test['itemID'] = test['Id'].apply(get_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#fits the algos on the full data set\n",
    "for algo in algos:\n",
    "    algo.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts with the effect of each coefficient defined\n",
    "preds = test.apply(lambda row: round( np.sum([coefs[i] * algos[i].predict(row.userID, row.itemID).est for i in range(len(coefs))] ) ), axis=1)\n",
    "test['Prediction'] = preds\n",
    "test = test.drop(['userID','itemID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('blend4BasicModels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
