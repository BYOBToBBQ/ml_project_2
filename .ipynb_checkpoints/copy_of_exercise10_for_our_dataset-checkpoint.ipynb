{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-30f52e30702c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# find the non-zero ratings for each user in the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnonzeros_train_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_ranges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m_get_row_ranges\u001b[0;34m(self, rows, col_slice)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mcol_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mnj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         _csparsetools.lil_get_row_ranges(self.shape[0], self.shape[1],\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_items, num_users = ratings.shape\n",
    "user_train_mean = np.array([])\n",
    "#calculates the mean for every movie\n",
    "for user_index in range(num_users):\n",
    "    # find the non-zero ratings for each user in the training dataset\n",
    "    train_ratings = ratings[:, user_index]\n",
    "    nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "    # calculate the mean if the number of elements is not 0\n",
    "    if nonzeros_train_ratings.shape[0] != 0:\n",
    "        user_train_mean = np.append(user_train_mean, nonzeros_train_ratings.mean() )\n",
    "\n",
    "    else:\n",
    "        user_train_mean.append(3)\n",
    "        print(\"exeption found \\n\")\n",
    "        continue\n",
    "#user_train_mean has the mean value for each movie\n",
    "np.shape(user_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train_mean = np.array([])\n",
    "#calculates the mean for every user    \n",
    "for item_index in range(num_items):\n",
    "    # find the non-zero ratings for each item in the training dataset\n",
    "    train_ratings = ratings[item_index, :]\n",
    "    nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "    # calculate the mean if the number of elements is not 0\n",
    "    if nonzeros_train_ratings.shape[0] != 0:\n",
    "        item_train_mean = np.append(item_train_mean, nonzeros_train_ratings.mean())\n",
    "    else:\n",
    "        item_train_mean.append(3)\n",
    "        print(\"exeption found \\n\")\n",
    "        continue\n",
    "#item_train_mean has the mean values for each user\n",
    "np.shape(item_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(user_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrmines which ID we need in our model\n",
    "ids_text = np.genfromtxt(\"examples_sample_submission.csv\", delimiter=\",\", skip_header=1, dtype=str, usecols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids():\n",
    "    \"\"\"\n",
    "    gets the idea for which we want to estimate the ratings\n",
    "    returns ids array (n,2) where, 1rs col is r and 2nd is c\n",
    "    \"\"\"\n",
    "    #fucntion transform r23c890 to 23, 890\n",
    "    def deal_line(line):\n",
    "        row, col = line.split('_')\n",
    "        row = row.replace(\"r\", \"\")\n",
    "        col = col.replace(\"c\", \"\")\n",
    "        return int(row), int(col)\n",
    "    \n",
    "    #determines which ID we need in our model\n",
    "    ids_text = np.genfromtxt(\"examples_sample_submission.csv\", delimiter=\",\", skip_header=1, dtype=str, usecols=0)\n",
    "    \n",
    "    # parse each line\n",
    "    ids = [deal_line(line) for line in ids_text]\n",
    "    \n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = get_ids()\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion transform r23c890 to 23, 890\n",
    "def deal_line(line):\n",
    "    row, col = line.split('_')\n",
    "    row = row.replace(\"r\", \"\")\n",
    "    col = col.replace(\"c\", \"\")\n",
    "    return int(row), int(col)\n",
    "\n",
    "\n",
    "# parse each line\n",
    "ids = [deal_line(line) for line in ids_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the submission file and puts in the values we want\n",
    "with open(\"averageOfMeanMovieAndUser.csv\", 'w') as csvfile:\n",
    "    fieldnames = ['Id', 'Prediction']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    i=0\n",
    "    for r, c in ids:\n",
    "        writer.writerow({'Id':ids_text[i],'Prediction':int((user_train_mean[c-1] + item_train_mean[r-1])/2)})\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useless function\n",
    "def create_csv_submission(data):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: data ()\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from plots import plot_raw_data\n",
    "\n",
    "def plot_raw_data(ratings):\n",
    "    \"\"\"plot the statistics result on raw rating data.\"\"\"\n",
    "    # do statistics.\n",
    "    num_users_per_item = np.array((ratings != 0).sum(axis=0)).flatten()\n",
    "    num_items_per_user = np.array((ratings != 0).sum(axis=1).T).flatten()\n",
    "    sorted_num_movies_per_user = np.sort(num_items_per_user)[::-1]\n",
    "    sorted_num_users_per_movie = np.sort(num_users_per_item)[::-1]\n",
    "    print(np.shape(sorted_num_movies_per_user), np.shape(sorted_num_users_per_movie))\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(sorted_num_users_per_movie, color='blue')\n",
    "    ax1.set_xlabel(\"movies\")\n",
    "    ax1.set_ylabel(\"number of ratings (sorted)\")\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(sorted_num_movies_per_user)\n",
    "    ax2.set_xlabel(\"users\")\n",
    "    ax2.set_ylabel(\"number of ratings (sorted)\")\n",
    "    ax2.set_xticks(np.arange(0, 10001, 2500))\n",
    "    ax2.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"stat_ratings\")\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    return num_items_per_user, num_users_per_item\n",
    "\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of baseline using the global mean: [[1.12152228]].\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # find the non zero ratings in the train\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "\n",
    "    # calculate the global mean\n",
    "    global_mean_train = nonzero_train.mean()\n",
    "\n",
    "    # find the non zero ratings in the test\n",
    "    nonzero_test = test[test.nonzero()].todense()\n",
    "\n",
    "    # predict the ratings as global mean\n",
    "    mse = calculate_mse(nonzero_test, global_mean_train)\n",
    "    rmse = np.sqrt(1.0 * mse / nonzero_test.shape[1])\n",
    "    print(\"test RMSE of baseline using the global mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the user mean: [[1.03317038]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "\n",
    "    for user_index in range(num_users):\n",
    "        # find the non-zero ratings for each user in the training dataset\n",
    "        train_ratings = train[:, user_index]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            user_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each user in the test dataset\n",
    "        test_ratings = test[:, user_index]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, user_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the user mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9990x999 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1176873 stored elements in LInked List format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8d6dd88d75f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[1;32m    421\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t3.0\n",
      "  (0, 5)\t5.0\n",
      "  (0, 7)\t4.0\n",
      "  (0, 21)\t5.0\n",
      "  (0, 31)\t5.0\n",
      "  (0, 33)\t4.0\n",
      "  (0, 43)\t4.0\n",
      "  (0, 44)\t3.0\n",
      "  (0, 47)\t4.0\n",
      "  (0, 59)\t3.0\n",
      "  (0, 60)\t4.0\n",
      "  (0, 69)\t2.0\n",
      "  (0, 71)\t4.0\n",
      "  (0, 80)\t4.0\n",
      "  (0, 88)\t5.0\n",
      "  (0, 92)\t3.0\n",
      "  (0, 94)\t4.0\n",
      "  (0, 101)\t5.0\n",
      "  (0, 134)\t1.0\n",
      "  (0, 137)\t2.0\n",
      "  (0, 143)\t2.0\n",
      "  (0, 160)\t3.0\n",
      "  (0, 168)\t2.0\n",
      "  (0, 172)\t3.0\n",
      "  (0, 176)\t2.0\n",
      "  (0, 181)\t4.0\n",
      "  (0, 187)\t4.0\n",
      "  (0, 190)\t4.0\n",
      "  (0, 212)\t5.0\n",
      "  (0, 214)\t5.0\n",
      "  (0, 219)\t3.0\n",
      "  (0, 221)\t5.0\n",
      "  (0, 225)\t3.0\n",
      "  (0, 227)\t2.0\n",
      "  (0, 239)\t3.0\n",
      "  (0, 256)\t4.0\n",
      "  (0, 257)\t5.0\n",
      "  (0, 282)\t2.0\n",
      "  (0, 284)\t2.0\n",
      "  (0, 287)\t1.0\n",
      "  (0, 294)\t3.0\n",
      "  (0, 303)\t4.0\n",
      "  (0, 305)\t4.0\n",
      "  (0, 309)\t3.0\n",
      "  (0, 313)\t5.0\n",
      "  (0, 316)\t5.0\n",
      "  (0, 336)\t2.0\n",
      "  (0, 337)\t3.0\n",
      "  (0, 349)\t5.0\n",
      "  (0, 362)\t3.0\n",
      "  (0, 364)\t4.0\n",
      "  (0, 365)\t5.0\n",
      "  (0, 367)\t3.0\n",
      "  (0, 375)\t4.0\n",
      "  (0, 384)\t4.0\n",
      "  (0, 387)\t4.0\n",
      "  (0, 395)\t4.0\n",
      "  (0, 396)\t3.0\n",
      "  (0, 401)\t5.0\n",
      "  (0, 433)\t5.0\n",
      "  (0, 439)\t1.0\n",
      "  (0, 442)\t3.0\n",
      "  (0, 443)\t1.0\n",
      "  (0, 456)\t4.0\n",
      "  (0, 457)\t3.0\n",
      "  (0, 458)\t4.0\n",
      "  (0, 464)\t5.0\n",
      "  (0, 474)\t5.0\n",
      "  (0, 476)\t5.0\n",
      "  (0, 477)\t5.0\n",
      "  (0, 484)\t2.0\n",
      "  (0, 491)\t5.0\n",
      "  (0, 494)\t5.0\n",
      "  (0, 507)\t4.0\n",
      "  (0, 521)\t2.0\n",
      "  (0, 524)\t4.0\n",
      "  (0, 533)\t4.0\n",
      "  (0, 548)\t2.0\n",
      "  (0, 555)\t3.0\n",
      "  (0, 570)\t5.0\n",
      "  (0, 575)\t2.0\n",
      "  (0, 582)\t3.0\n",
      "  (0, 583)\t5.0\n",
      "  (0, 591)\t3.0\n",
      "  (0, 593)\t5.0\n",
      "  (0, 596)\t5.0\n",
      "  (0, 605)\t5.0\n",
      "  (0, 607)\t5.0\n",
      "  (0, 608)\t5.0\n",
      "  (0, 610)\t3.0\n",
      "  (0, 611)\t5.0\n",
      "  (0, 617)\t5.0\n",
      "  (0, 618)\t5.0\n",
      "  (0, 619)\t5.0\n",
      "  (0, 623)\t2.0\n",
      "  (0, 626)\t4.0\n",
      "  (0, 631)\t5.0\n",
      "  (0, 632)\t5.0\n",
      "  (0, 639)\t5.0\n",
      "  (0, 641)\t5.0\n",
      "  (0, 642)\t3.0\n",
      "  (0, 655)\t5.0\n",
      "  (0, 657)\t4.0\n",
      "  (0, 658)\t5.0\n",
      "  (0, 659)\t5.0\n",
      "  (0, 667)\t4.0\n",
      "  (0, 670)\t5.0\n",
      "  (0, 672)\t1.0\n",
      "  (0, 689)\t5.0\n",
      "  (0, 693)\t3.0\n",
      "  (0, 694)\t5.0\n",
      "  (0, 696)\t5.0\n",
      "  (0, 699)\t4.0\n",
      "  (0, 715)\t3.0\n",
      "  (0, 724)\t5.0\n",
      "  (0, 726)\t5.0\n",
      "  (0, 747)\t5.0\n",
      "  (0, 768)\t5.0\n",
      "  (0, 775)\t2.0\n",
      "  (0, 778)\t5.0\n",
      "  (0, 784)\t4.0\n",
      "  (0, 788)\t1.0\n",
      "  (0, 790)\t3.0\n",
      "  (0, 792)\t3.0\n",
      "  (0, 803)\t4.0\n",
      "  (0, 804)\t3.0\n",
      "  (0, 807)\t2.0\n",
      "  (0, 814)\t4.0\n",
      "  (0, 818)\t5.0\n",
      "  (0, 821)\t3.0\n",
      "  (0, 824)\t4.0\n",
      "  (0, 826)\t5.0\n",
      "  (0, 840)\t4.0\n",
      "  (0, 847)\t4.0\n",
      "  (0, 849)\t4.0\n",
      "  (0, 863)\t3.0\n",
      "  (0, 866)\t4.0\n",
      "  (0, 870)\t2.0\n",
      "  (0, 881)\t5.0\n",
      "  (0, 889)\t3.0\n",
      "  (0, 949)\t3.0\n",
      "  (0, 966)\t2.0\n",
      "  (0, 973)\t5.0\n",
      "  (0, 980)\t5.0\n",
      "  (0, 982)\t4.0\n",
      "  (0, 984)\t3.0\n",
      "  (0, 997)\t5.0\n",
      "  (0, 998)\t3.0\n",
      "  (0, 999)\t3.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
