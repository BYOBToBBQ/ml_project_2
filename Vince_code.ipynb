{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hyperparameters tuning and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import plots\n",
    "from matplotlib import pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SlopeOne\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from Vince_helpers import *\n",
    "\n",
    "my_seed = 200\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data train file\n",
    "train = pd.read_csv('data_train.csv')\n",
    "train = to_surprise(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into models training part and blender training part\n",
    "models = train.sample(frac=0.8, random_state=200)\n",
    "blend = train.drop(models.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load both datasets into surprise as datasets and trainsets objects\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "models_surp = Dataset.load_from_df(models, reader)\n",
    "models_surp_train = models_surp.build_full_trainset()\n",
    "blend_surp = Dataset.load_from_df(blend, reader)\n",
    "blend_surp_train = blend_surp.build_full_trainset()\n",
    "#Load blend train set as a testset for models performance evaluation\n",
    "blend_surp_test = blend_surp_train.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We grid search the best hyperparameters for each models individually on the models training set. We evaluate each combination based on a K=3 Fold CV procedure (folds are set to be the same every time for reproducibility). Then we will pick the combinations yielding the smallest average RMSE over the folds and refit the models on the whole models training data. Note that some models do not require tuning (global mean, user/item mean, slopeone) and will therefore be fitted directly on the whole models train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm tuning:\n",
    "- Establish Grid\n",
    "- Run Grid search\n",
    "- Extract best hyperparameters combination based on average RMSE\n",
    "- Retrain on the whole models train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic solutions: global mean, user mean and movie mean\n",
    "#Here we compute the mean or dataframes of means per users or movies\n",
    "mean = global_mean(models)\n",
    "users = user_mean(models)\n",
    "movies = movie_mean(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'bsl_options': {'method': 'sgd', 'reg': 1e-08}, 'verbose': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1a203e39b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline\n",
    "grid_baseline = {'bsl_options': {'method': ['sgd'],\n",
    "                              'reg': [10**-i for i in range(8,9)]},\n",
    "                 'verbose':[False]\n",
    "                }\n",
    "gs_baseline = GridSearchCV(BaselineOnly, grid_baseline, measures=['rmse'], \n",
    "                           cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_baseline.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_baseline.best_params['rmse'])\n",
    "algo_baseline = gs_baseline.best_estimator['rmse']\n",
    "algo_baseline.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'reg_all': 0.01, 'biased': True, 'n_factors': 100, 'random_state': 200}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a203e3780>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVD with baseline\n",
    "grid_SVDb = {'reg_all': [10**-i for i in range(1,2)], 'biased':[True], 'n_factors':[100], 'random_state':[200]}\n",
    "gs_SVDb = GridSearchCV(SVD, grid_SVDb, measures=['rmse'], \n",
    "                       cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_SVDb.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_SVDb.best_params['rmse'])\n",
    "algo_SVDb = gs_SVDb.best_estimator['rmse']\n",
    "algo_SVDb.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD without baseline\n",
    "grid_SVD = {'reg_all':[10**-i for i in range(1,2)], 'biased':[False], 'n_factors':[100], 'random_state':[200]}\n",
    "gs_SVD = GridSearchCV(SVD, grid_SVD, measures=['rmse'], \n",
    "                      cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_SVD.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_SVD.best_params['rmse'])\n",
    "algo_SVD = gs_SVD.best_estimator['rmse']\n",
    "algo_SVD.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD++\n",
    "grid_SVDpp = {'reg_all':[0.01], 'n_factors':[20], 'random_state':[200]}\n",
    "gs_SVDpp = GridSearchCV(SVDpp, grid_SVDpp, measures=['rmse'], \n",
    "                        cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_SVDpp.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_SVDpp.best_params['rmse'])\n",
    "algo_SVDpp = gs_SVDpp.best_estimator['rmse']\n",
    "algo_SVDpp.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.slope_one.SlopeOne at 0x1180126d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slope One\n",
    "algo_slope_one = SlopeOne()\n",
    "algo_slope_one.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN user\n",
    "grid_knn_user = {'bsl_options': {'method': ['sgd'],\n",
    "                              'reg': [10**-i for i in range(1,2)]},\n",
    "                              'k': [40],\n",
    "                              'sim_options': {'name': ['pearson_baseline'],\n",
    "                              'min_support': [1],\n",
    "                              'user_based': [True]}\n",
    "                }\n",
    "gs_knn_user = GridSearchCV(KNNBaseline, grid_knn_user, measures=['rmse'], \n",
    "                        cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_knn_user.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_knn_user.best_params['rmse'])\n",
    "algo_knn_user = gs_knn_user.best_estimator['rmse']\n",
    "algo_knn_user.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best Hyperparameters:  {'bsl_options': {'method': 'sgd', 'reg': 0.001}, 'k': 60, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x103fcac50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN movie\n",
    "grid_knn_movie = {'bsl_options': {'method': ['sgd'],\n",
    "                              'reg': [10**-i for i in range(3,4)]},\n",
    "                              'k': [60],\n",
    "                              'sim_options': {'name': ['pearson_baseline'],\n",
    "                              'min_support': [1],\n",
    "                              'user_based': [False]}\n",
    "                }\n",
    "gs_knn_movie = GridSearchCV(KNNBaseline, grid_knn_movie, measures=['rmse'], \n",
    "                        cv=KFold(n_splits=3, random_state=200, shuffle=False))\n",
    "gs_knn_movie.fit(models_surp)\n",
    "print('Best Hyperparameters: ', gs_knn_movie.best_params['rmse'])\n",
    "algo_knn_movie = gs_knn_movie.best_estimator['rmse']\n",
    "algo_knn_movie.fit(models_surp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that every algorithm has been fitted on the whole models train dataset we will evaluate their performance (RMSE) on the blend train dataset. This set is therefore also used as a validation set for individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set:  1.0032986221959859\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "predictions_baseline = algo_baseline.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_baseline, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set:  1.0647191794539996\n"
     ]
    }
   ],
   "source": [
    "#SVD with baseline\n",
    "predictions_SVDb = algo_SVDb.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_SVDb, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD without baseline\n",
    "predictions_SVD = algo_SVD.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_SVD, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD++\n",
    "predictions_SVDpp = algo_SVDpp.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_SVDpp, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slope One\n",
    "predictions_slope_one = algo_slope_one.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_slope_one, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN user\n",
    "predictions_knn_user = algo_knn_user.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_knn_user, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set:  0.9911173306703703\n"
     ]
    }
   ],
   "source": [
    "#KNN movie\n",
    "predictions_knn_movie = algo_knn_movie.test(blend_surp_test)\n",
    "print('RMSE on validation set: ', accuracy.rmse(predictions_knn_movie, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recover ids and estimations for each algorithm\n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "est_SVD = [pred.est for pred in predictions_SVD]\n",
    "#est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "#est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean RMSE on validation set:  1.119984536592249\n",
      "User mean RMSE on validation set:  1.095988679007401\n",
      "Movie mean RMSE on validation set:  1.0300326000124342\n"
     ]
    }
   ],
   "source": [
    "#RMSE on validation set for basic solutions\n",
    "global_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_global)])/len(ruis))\n",
    "user_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_user_mean)])/len(ruis))\n",
    "movie_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_movie_mean)])/len(ruis))\n",
    "print('Global mean RMSE on validation set: ', global_rmse)\n",
    "print('User mean RMSE on validation set: ', user_rmse)\n",
    "print('Movie mean RMSE on validation set: ', movie_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the blend train set to train our model blending algorithm. We model the estimated rating as a linear combination of estimated ratings for each model. We will resort to ridge regression to compute the weights of our model. The best ridge hyperparameter is picked based on a 3 fold CV procedure (objective function = average RMSE) operated on 75% of the blender train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build dataframe containing true ratings and estimations for each algorithm\n",
    "est_baseline = np.array(est_baseline)\n",
    "est_global = np.array(est_global)\n",
    "est_user_mean = np.array(est_user_mean)\n",
    "est_movie_mean = np.array(est_movie_mean)\n",
    "est_knn_movie = np.array(est_knn_movie)\n",
    "#est_knn_user = np.array(est_knn_user)\n",
    "est_slope_one = np.array(est_slope_one)\n",
    "est_SVDb = np.array(est_SVDb)\n",
    "est_SVD = np.array(est_SVD)\n",
    "#est_SVDpp = np.array(est_SVDpp)\n",
    "\n",
    "'''\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_knn_user, est_slope_one,\n",
    "                     est_SVDb, est_SVD, est_SVDpp))\n",
    "'''\n",
    "\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_slope_one,\n",
    "                     est_SVDb, est_SVD))\n",
    "\n",
    "y = np.array(ruis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the blend train set into a training set and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the grid search on the training set (i.e infer best lambda and weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ridge = skFold(n_splits=3, random_state=200)\n",
    "gs_ridge = RidgeCV(alphas=[10**-i for i in range(-5,10)], fit_intercept=False, scoring=\"neg_mean_squared_error\", cv=cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  10.0\n",
      "Weights:  [-0.04315075 -0.11769155  0.07828077  0.24455342  0.75458397  0.07984848]\n"
     ]
    }
   ],
   "source": [
    "gs_ridge.fit(X_train, y_train)\n",
    "print('Best lambda: ', gs_ridge.alpha_)\n",
    "print('Weights: ', gs_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the validation set RMSE for the blending model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_blend = gs_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model blending RMSE on validation set:  0.9855245790114191\n"
     ]
    }
   ],
   "source": [
    "blend_rmse = np.sqrt(np.mean((y_test-preds_blend)**2))\n",
    "print('Model blending RMSE on validation set: ', blend_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found the best hyperparameters for each model and the coefficients for the blending algorithm. We will now retrain our algorithms on the whole dataset. Then final predictions will be a linear combination of predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
