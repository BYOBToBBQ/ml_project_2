{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CrowdAI submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import plots\n",
    "from matplotlib import pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SlopeOne\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from Vince_helpers import *\n",
    "\n",
    "my_seed = 200\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data train file\n",
    "train = pd.read_csv('data_train.csv')\n",
    "train = to_surprise(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train set into Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_surp = Dataset.load_from_df(train, reader)\n",
    "train_surp = train_surp.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit each model with preselected hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = global_mean(train)\n",
    "users = user_mean(train)\n",
    "movies = movie_mean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "algo_baseline = BaselineOnly().fit(train_surp)\n",
    "algo_SVDb = SVD().fit(train_surp)\n",
    "algo_SVD = SVD().fit(train_surp)\n",
    "#algo_SVDpp = SVDpp().fit(train_surp)\n",
    "algo_slope_one = SlopeOne().fit(train_surp)\n",
    "#algo_knn_user = KNNBaseline().fit(train_surp)\n",
    "algo_knn_movie = KNNBaseline().fit(train_surp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user/movie pairs to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.read_csv('examples_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move testset to surprise testset format\n",
    "test = test_original.copy()\n",
    "test = to_surprise(test)\n",
    "test = Dataset.load_from_df(test, reader)\n",
    "test = test.build_full_trainset()\n",
    "test = test.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.56 s, sys: 307 ms, total: 7.87 s\n",
      "Wall time: 7.88 s\n",
      "CPU times: user 11 s, sys: 326 ms, total: 11.3 s\n",
      "Wall time: 11.4 s\n",
      "CPU times: user 10.6 s, sys: 262 ms, total: 10.8 s\n",
      "Wall time: 10.8 s\n",
      "CPU times: user 2min 40s, sys: 848 ms, total: 2min 40s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "#Predict ratings with every model\n",
    "predictions_baseline = algo_baseline.test(test)\n",
    "predictions_SVDb = algo_SVDb.test(test)\n",
    "predictions_SVD = algo_SVD.test(test)\n",
    "#predictions_SVDpp = algo_SVDpp.test(test)\n",
    "predictions_slope_one = algo_slope_one.test(test)\n",
    "#predictions_knn_user = algo_knn_user.test(test)\n",
    "#predictions_knn_movie = algo_knn_movie.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract estimated ratings\n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "est_SVD = [pred.est for pred in predictions_SVD]\n",
    "#est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "#est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "#est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Dataframe containing ratings predictions\n",
    "est_baseline = np.array(est_baseline)\n",
    "est_global = np.array(est_global)\n",
    "est_user_mean = np.array(est_user_mean)\n",
    "est_movie_mean = np.array(est_movie_mean)\n",
    "#est_knn_movie = np.array(est_knn_movie)\n",
    "#est_knn_user = np.array(est_knn_user)\n",
    "est_slope_one = np.array(est_slope_one)\n",
    "est_SVDb = np.array(est_SVDb)\n",
    "est_SVD = np.array(est_SVD)\n",
    "#est_SVDpp = np.array(est_SVDpp)\n",
    "\n",
    "'''\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_knn_user, est_slope_one,\n",
    "                     est_SVDb, est_SVD, est_SVDpp))\n",
    "'''\n",
    "\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_slope_one, est_SVDb, est_SVD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear combination of predictions\n",
    "weights = np.array([0.1428]*7)\n",
    "#weights = np.array([0.1]*10)\n",
    "preds = X.dot(weights)\n",
    "#Clip interval to 1-5 and round predictions to nearest integer\n",
    "preds = np.clip(preds, 1, 5)\n",
    "preds = np.around(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recover proper ids format\n",
    "ids = np.array(['r'+str(u)+'_c'+str(m) for (u,m) in zip(uids, mids)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Id':ids, 'Prediction':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('subVince', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
