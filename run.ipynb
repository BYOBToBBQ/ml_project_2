{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CrowdAI submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import plots\n",
    "from matplotlib import pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SlopeOne\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from Vince_helpers import *\n",
    "\n",
    "#Reproducibility\n",
    "my_seed = 200\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data train file\n",
    "train = pd.read_csv('data_train.csv')\n",
    "train = to_surprise(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train set into Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_surp = Dataset.load_from_df(train, reader)\n",
    "train_surp = train_surp.build_full_trainset()\n",
    "train_surp_test = train_surp.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit each model with preselected hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = global_mean(train)\n",
    "users = user_mean(train)\n",
    "movies = movie_mean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set previously computed hyperparameters for each algorithm\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'reg': 10**-8\n",
    "              }\n",
    "bsl_options_knnu = {'method': 'als',\n",
    "                    'n_epochs': 50,\n",
    "                   }\n",
    "sim_options_knnu = {'name': 'pearson_baseline', 'user_based' : True\n",
    "                   }\n",
    "bsl_options_knni = {'method': 'als',\n",
    "                    'n_epochs': 50,\n",
    "                   }\n",
    "sim_options_knni = {'name': 'pearson_baseline', 'user_based' : False\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit algorithms on the whole training data with the previousy\n",
    "algo_baseline = BaselineOnly(bsl_options=bsl_options).fit(train_surp)\n",
    "algo_SVDb = SVD(n_factors=400, lr_all=0.0015, biased=True, reg_all=0.1, n_epochs=500, random_state=200).fit(train_surp)\n",
    "algo_SVD = SVD(reg_all=0.01, biased=False, n_factors=1, lr_all=0.0015, n_epochs=500, random_state=200).fit(train_surp)\n",
    "algo_SVDpp = SVDpp(random_state=200).fit(train_surp)\n",
    "algo_slope_one = SlopeOne().fit(train_surp)\n",
    "algo_knn_user = KNNBaseline(k=250, sim_options=sim_options_knnu, bsl_options=bsl_options_knnu).fit(train_surp)\n",
    "algo_knn_movie = KNNBaseline(k=250, sim_options=sim_options_knni, bsl_options=bsl_options_knni).fit(train_surp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to test set predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user/movie pairs to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.read_csv('examples_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move testset to surprise testset format\n",
    "test = test_original.copy()\n",
    "test = to_surprise(test)\n",
    "test = Dataset.load_from_df(test, reader)\n",
    "test = test.build_full_trainset()\n",
    "test = test.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict ratings with every model\n",
    "predictions_baseline = algo_baseline.test(test)\n",
    "predictions_SVDb = algo_SVDb.test(test)\n",
    "predictions_SVD = algo_SVD.test(test)\n",
    "predictions_SVDpp = algo_SVDpp.test(test)\n",
    "predictions_slope_one = algo_slope_one.test(test)\n",
    "predictions_knn_user = algo_knn_user.test(test)\n",
    "predictions_knn_movie = algo_knn_movie.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract estimated ratings\n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "est_SVD = [pred.est for pred in predictions_SVD]\n",
    "est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Dataframe containing ratings predictions\n",
    "est_baseline = np.array(est_baseline)\n",
    "est_global = np.array(est_global)\n",
    "est_user_mean = np.array(est_user_mean)\n",
    "est_movie_mean = np.array(est_movie_mean)\n",
    "est_knn_movie = np.array(est_knn_movie)\n",
    "est_knn_user = np.array(est_knn_user)\n",
    "est_slope_one = np.array(est_slope_one)\n",
    "est_SVDb = np.array(est_SVDb)\n",
    "est_SVD = np.array(est_SVD)\n",
    "est_SVDpp = np.array(est_SVDpp)\n",
    "\n",
    "\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_knn_user, est_slope_one,\n",
    "                     est_SVDb, est_SVD, est_SVDpp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear combination of predictions\n",
    "#Weights previously computed\n",
    "weights = np.array([0.12650389, -0.24258255, -0.11721048, -0.0233713, \n",
    "                    0.15383295,  0.16873745,  0.16240169,  1.03262748, \n",
    "                    -0.39005349,  0.12686713])\n",
    "preds = X.dot(weights)\n",
    "#Clip interval to 1-5 and round predictions to nearest integer\n",
    "preds = np.clip(preds, 1, 5)\n",
    "preds = np.around(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recover proper ids format\n",
    "ids = np.array(['r'+str(u)+'_c'+str(m) for (u,m) in zip(uids, mids)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Id':ids, 'Prediction':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('subVince', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
